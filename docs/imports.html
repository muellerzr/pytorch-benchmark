---

title: Imports


keywords: fastai
sidebar: home_sidebar

summary: "Import utilities to check library availability "
description: "Import utilities to check library availability "
nb_path: "nbs/00_imports.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00_imports.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This module contains helper functions that check if various environmental factors are available</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_tpu_available" class="doc_header"><code>is_tpu_available</code><a href="https://github.com/muellerzr/pytorch-benchmark/pytorch_benchmark/imports.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_tpu_available</code>(<strong><code>check_device</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>Checks if <code>torch_xla</code> is installed and potentially if a TPU is in the environment</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_bf16_available" class="doc_header"><code>is_bf16_available</code><a href="https://github.com/muellerzr/pytorch-benchmark/pytorch_benchmark/imports.py#L38" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_bf16_available</code>(<strong><code>ignore_tpu</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Checks if bf16 is supported, optionally ignoring the TPU</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="is_multigpu_available" class="doc_header"><code>is_multigpu_available</code><a href="https://github.com/muellerzr/pytorch-benchmark/pytorch_benchmark/imports.py#L48" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>is_multigpu_available</code>()</p>
</blockquote>
<p>Checks if number of cuda devices available &gt; 1</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

