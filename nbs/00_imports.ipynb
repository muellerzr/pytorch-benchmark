{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734e739-82af-441c-862c-9e5b09791fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c4c67-31f4-4440-a948-dcf9b23bacd5",
   "metadata": {},
   "source": [
    "# Imports\n",
    "> Import utilities to check library availability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3fd9d-a248-4210-9181-90c7572fe4a3",
   "metadata": {},
   "source": [
    "This module contains helper functions that check if various environmental factors are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e250ec-18d2-44a8-9b0d-15f1af8cd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys, operator, torch\n",
    "from packaging.version import Version, parse\n",
    "\n",
    "if sys.version_info < (3, 8):\n",
    "    import importlib_metadata\n",
    "else:\n",
    "    import importlib.metadata as importlib_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff18ccdf-9fc8-4ef9-af4a-5bc8c3cf1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm  # noqa: F401\n",
    "\n",
    "    _tpu_available = True\n",
    "except ImportError:\n",
    "    _tpu_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f0b362-e281-40bb-aa46-1ec109589f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_torch_version = parse(importlib_metadata.version(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8e3e094-1dda-4e33-835c-c49b4dd1e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_tpu_available(check_device=True) -> bool:\n",
    "    \"Checks if `torch_xla` is installed and potentially if a TPU is in the environment\"\n",
    "    if _tpu_available and check_device:\n",
    "        try:\n",
    "            # Will raise a RuntimeError if no XLA configuration is found\n",
    "            _ = xm.xla_device()\n",
    "            return True\n",
    "        except RuntimeError:\n",
    "            return False\n",
    "    return _tpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4447c3f7-c591-41c4-96b5-2f688563fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_bf16_available(ignore_tpu=False):\n",
    "    \"Checks if bf16 is supported, optionally ignoring the TPU\"\n",
    "    if is_tpu_available(): return not ignore_tpu\n",
    "    if operator.ge(_torch_version, Version(\"1.10\")):\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.cuda.is_bf16_supported()\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a48951ec-4bab-4a95-a0fc-10ea7bdc01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_multigpu_available() -> bool:\n",
    "    \"Checks if number of cuda devices available > 1\"\n",
    "    return torch.cuda.is_available() and torch.cuda.device_count() > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe4fbd8-ab9c-4872-975c-d6667d0a2fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No export destination, ignored:\n",
      "#export\n",
      "import sys, operator, torch\n",
      "from packaging.version import Version, parse\n",
      "\n",
      "if sys.version_info < (3, 8):\n",
      "    import importlib_metadata\n",
      "else:\n",
      "    import importlib.metadata as importlib_metadata\n",
      "No export destination, ignored:\n",
      "#export\n",
      "try:\n",
      "    import torch_xla.core.xla_model as xm  # noqa: F401\n",
      "\n",
      "    _tpu_available = True\n",
      "except ImportError:\n",
      "    _tpu_available = False\n",
      "No export destination, ignored:\n",
      "#export\n",
      "_torch_version = parse(importlib_metadata.version(\"torch\"))\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def is_tpu_available(check_device=True) -> bool:\n",
      "    \"Checks if `torch_xla` is installed and potentially if a TPU is in the environment\"\n",
      "    if _tpu_available and check_device:\n",
      "        try:\n",
      "            # Will raise a RuntimeError if no XLA configuration is found\n",
      "            _ = xm.xla_device()\n",
      "            return True\n",
      "        except RuntimeError:\n",
      "            return False\n",
      "    return _tpu_available\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def is_bf16_available(ignore_tpu=False):\n",
      "    \"Checks if bf16 is supported, optionally ignoring the TPU\"\n",
      "    if is_tpu_available(): return not ignore_tpu\n",
      "    if operator.ge(_torch_version, Version(\"1.10\")):\n",
      "        if torch.cuda.is_available():\n",
      "            return torch.cuda.is_bf16_supported()\n",
      "        return True\n",
      "    return False\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def is_multigpu_available() -> bool:\n",
      "    \"Checks if number of cuda devices available > 1\"\n",
      "    return torch.cuda.is_available() and torch.cuda.device_count() > 1\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook2script\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnotebook2script\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbdev/export.py:445\u001b[0m, in \u001b[0;36mnotebook2script\u001b[0;34m(fname, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    443\u001b[0m d \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m to_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    444\u001b[0m modules \u001b[38;5;241m=\u001b[39m create_mod_files(files, to_dict, bare\u001b[38;5;241m=\u001b[39mbare)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(files): d \u001b[38;5;241m=\u001b[39m \u001b[43m_notebook2script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_dict: \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: add_init(get_config()\u001b[38;5;241m.\u001b[39mpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib_path\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbdev/export.py:372\u001b[0m, in \u001b[0;36m_notebook2script\u001b[0;34m(fname, modules, silent, to_dict, bare)\u001b[0m\n\u001b[1;32m    370\u001b[0m code \u001b[38;5;241m=\u001b[39m _from_future_import(fname_out, flags, code, to_dict)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43m_add2all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mf\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m mod\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mupdate({f: fname\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m names})\n\u001b[1;32m    374\u001b[0m code \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m +$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, code, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbdev/export.py:215\u001b[0m, in \u001b[0;36m_add2all\u001b[0;34m(fname, names, line_width)\u001b[0m\n\u001b[1;32m    213\u001b[0m tw \u001b[38;5;241m=\u001b[39m TextWrapper(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, initial_indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, subsequent_indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m11\u001b[39m, break_long_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m re_all \u001b[38;5;241m=\u001b[39m _re__all__def\u001b[38;5;241m.\u001b[39msearch(text)\n\u001b[0;32m--> 215\u001b[0m start,end \u001b[38;5;241m=\u001b[39m \u001b[43mre_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m(),re_all\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    216\u001b[0m text_all \u001b[38;5;241m=\u001b[39m tw\u001b[38;5;241m.\u001b[39mwrap(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[start:end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text[end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: f\u001b[38;5;241m.\u001b[39mwrite(text[:start] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text_all) \u001b[38;5;241m+\u001b[39m text[end:])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccf5f6-608c-4dc0-ae51-702f7566a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
