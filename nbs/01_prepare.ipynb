{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438daa7-f23d-4edc-9470-d373152c65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974b53f-6e28-477a-bbce-1a32ab14d5d8",
   "metadata": {},
   "source": [
    "# PyTorch Preprocessors\n",
    "> Module for preprocessing torch classes to prepare for various distributed environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b20e7-4dc9-417e-a5a7-d73c5876916a",
   "metadata": {},
   "source": [
    "This module is what is essentially a barebones version of [Accelerate](https://github.com/huggingface/accelerate) but it only affects the outer-most layer of the modules for what is needed in these tests.\n",
    "\n",
    "So for example dispatched dataloaders are not a part of this, nor affecting the underlying dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5d6bfd-4b2d-4f73-bf99-06c6fe7f977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pytorch_benchmark.imports import is_tpu_available, is_multigpu_available\n",
    "from pytorch_benchmark.utils import get_device, get_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b70437b-ff66-40eb-b988-730e62332cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, torch\n",
    "from torch import nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if is_tpu_available(check_device=False):\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3fe16f",
   "metadata": {},
   "source": [
    "## Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f5154a-36b6-4892-8522-fae8e435e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_model(\n",
    "    model:nn.Module, # A PyTorch model to wrap\n",
    "    **kwargs\n",
    "):\n",
    "    \"Prepares a model for distributed training. kwargs are sent to DDP\"\n",
    "    if is_tpu_available():\n",
    "        return xmp.MpModelWrapper(model)\n",
    "    elif is_multigpu_available():\n",
    "        return DDP(model, device_ids=[get_rank()], output_device=get_rank())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46d9caf-4e42-4fb3-8cc5-b967abae8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OptimizerInterface(torch.optim.Optimizer):\n",
    "    \"Basic optimizer wrapper that performs the right step call for TPU\"\n",
    "    def __init__(self, optimizer):\n",
    "        self.opt = optimizer\n",
    "\n",
    "    @property\n",
    "    def state(self): return self.opt.state\n",
    "\n",
    "    @state.setter\n",
    "    def state(self, state): self.opt.state = state\n",
    "\n",
    "    @property\n",
    "    def defaults(self): return self.opt.defaults\n",
    "\n",
    "    @defaults.setter\n",
    "    def defaults(self, defaults): self.opt.defaults = defaults\n",
    "\n",
    "    def state_dict(self): \n",
    "        \"Passthrough to state dict\"\n",
    "        return self.opt.state_dict()\n",
    "\n",
    "    def zero_grad(self): \n",
    "        \"Passthrough to zero_grad\"\n",
    "        return self.opt.zero_grad()\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"Passthrough unless on TPU then calls the right stepper\"\n",
    "        if is_tpu_available():\n",
    "            xm.optimizer_step(self.opt, {})\n",
    "        self.opt.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f834c6f-7098-489f-b11e-6437989047f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_optimizer(\n",
    "    opt:torch.optim.Optimizer\n",
    "):\n",
    "    return OptimizerInterface(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "440258fe-07b9-4e5b-9bf2-d99275f8301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SchedulerInterface:\n",
    "    \"Wrapper to step the scheduler the right number of times\"\n",
    "    def __init__(self, scheduler, num_processes):\n",
    "        self.scheduler = scheduler\n",
    "        self.num_processes = num_processes\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        \"Passthrough to `scheduler.step` but will also step the right number of times\"\n",
    "        for _ in range(self.num_processes):\n",
    "            if getattr(self.scheduler, \"total_steps\", 0) <= self.scheduler.last_epoch:\n",
    "                self.scheduler.step(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25bede9-ff02-42da-a20b-bd2582913faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_scheduler(\n",
    "    sched:torch.optim.lr_scheduler._LRScheduler\n",
    "):\n",
    "    if is_tpu_available():\n",
    "        num_processes = 8 # hard coded for my tests\n",
    "    elif is_multigpu_available():\n",
    "        num_processes = torch.cuda.device_count()\n",
    "    else:\n",
    "        num_processes = 1\n",
    "    return SchedulerInterface(sched, num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe9aac-115d-4cfd-98a4-f4f710fff12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _prepare_one(obj, first_pass=False):\n",
    "    # first pass on preperation: DataLoader, model, optimizer\n",
    "    if first_pass:\n",
    "        if isinstance(obj, torch.nn.Module):\n",
    "            return prepare_model(obj)\n",
    "        elif isinstance(obj, torch.optim.Optimizer):\n",
    "            return prepare_optimizer(obj)\n",
    "    elif isinstance(obj, torch.optim.lr_scheduler._LRScheduler):\n",
    "        return prepare_scheduler(obj)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb215f1-8064-4727-a703-06ff9167754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_modules(*modules):\n",
    "    \"Prepares a set of modules, supports only PyTorch models, optimizers, and schedulers\"\n",
    "    result = tuple(_prepare_one(obj, first_pass=True) for obj in modules)\n",
    "    return tuple(_prepare_one(obj) for obj in result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62257b2",
   "metadata": {},
   "source": [
    "## Interfaces\n",
    "\n",
    "The interface classes `prepare_modules` may wrap around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e48734",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizerInterface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizerInterface.state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a471912",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizerInterface.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(OptimizerInterface.zero_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SchedulerInterface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SchedulerInterface.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c4908db-887e-4b26-85b4-589b0d09bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_imports.ipynb.\n",
      "Converted 01_prepare.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b308c-34ce-4fdf-b92f-e8f2b441f2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
